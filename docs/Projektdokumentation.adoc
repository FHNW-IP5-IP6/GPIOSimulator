:toc: macro
:toc-title:
:toclevels: 5
:sectnums:
:sectnumlevels: 5
:sourcedir: ../src/main/java
:imagesdir: ./assets/images
:iconsdir: ./icons
:stylesdir: ./styles
:homepage: https://github.com/FHNW-IP5-IP6/GPIOSimulator

image::FHNW.png[FHNW,382,59]
[discrete]
= IP5: GPIOSimoulator

*Semesterarbeit von*:

* Herr Jonathan Bättig (jonathan.baettig@students.fhnw.ch) 
* Herr Anessollah Ima (anessollah.ima@students.fhnw.ch)

*FHNW* +
*Hochschule für Technik* +
*Studiengang* : Informatik +
*Semester* : 6BB

*Betreuende Dozenten*:

* Frau Dr. Barbara Scheuner (barbara.scheuner@fhnw.ch) 
* Herr Dr. Dieter Holz (dieter.holz@fhnw.ch) 

*Datum*: {docdate}


<<<
[discrete]
== TODO: Summary
TBD am Ende: + 
Anhand dieses Textes soll eine Person entscheiden können, ob sie sich für ihr Thema interessiert.

. Was wurde erreicht?
. Was sind die Ergebnisse
. Warum wurde es gemacht? Was war das Problem? 
. Wie wurde es gemacht/untersucht/getestet?

<<<
[discrete]
== TODO: Vorwort

<<<
[discrete]
== Inhaltsverzeichnis
toc::[]

<<<
:sectnums!:
== TODO: Einleitung
:sectnums:

<<<
== Theoretischer Teil

=== Anforderungen
Die nachfolgende Tabelle enthält alle Anforderungen an den GPIO Simulator, welche wir während der Requirement Analyse identifizieren haben. Den einzelnen Anforderungen haben wir drei Prioriäten zugeteilt.

* *Priorität 1*: Anforderungen an den MVP
* *Priorität 2*: Unterstützung der Grove Sensoren
* *Priorität 3*: Implementation User Interface

Die Umsetzung der Requirements soll gemäss Ihrer Priorität erfolgen.

.Anforderungen
[cols="1,7,1"]
|===
|Nummer |Beschreibung  |Priorität

|{counter:reqNumber} 
|Anwender sollen unabhängig von der Hardwareverfügbarkeit an ihren Raspberry Pi Projekten arbeiten können.
|1

|{counter:reqNumber}
|Anwender sollen auf eine einfache und intuitive Art konfigurieren können, ob der Code auf dem GPIO Simulator oder auf dem Raspberry Pi ausgeführt wird.
|1

|{counter:reqNumber}
|Anwender sollen das Logging Level des GPIO Simulators konfigurieren können, ohne dass das Projekt neu gebaut werden muss.
|1

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die analogen und digitalen Pins des Raspberry Pi via Pi4J setzen können.
|1

|{counter:reqNumber} 
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die analogen und digitalen Pins des GPIO Simulators setzen können.
|1

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die analogen und digitalen Pins des Raspberry Pi via Pi4J auslesen können.
|1

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die analogen und digitalen Pins des GPIO Simulators auslesen können.
|1

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die Grove Anschlüsse des Raspberry Pi via Pi4J setzen können.
|2

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die Grove Anschlüsse des GPIO Simulators setzen können.
|2

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die Grove Anschlüsse des Raspberry Pi via Pi4J auslesen können.
|2

|{counter:reqNumber}
|Anwender sollen mittels den vom GPIO Simulator zur Verfügung gestellten Funktionen die Grove Anschlüsse des GPIO Simulators auslesen können.
|2

|{counter:reqNumber}
|Den Benutzern des GPIO Simulators sollen Code Beispiele für die gängigen Sensoren und Aktuatoren zur Verfügung stehen.
|2

|{counter:reqNumber}
|Anwender sollen vom GPIO Simulator Feedback in einem User Interface erhalten.
|3

|{counter:reqNumber} 
|Anwender sollen im User Interface des GPIO Simulators alle gängigen Sensoren und Aktuatoren zur Verfügung haben.
|3

|{counter:reqNumber}
|Anwender sollen im User Interface des GPIO Simulators Sensoren und Aktuatoren mit dem Grove Hat verbinden können.
|3

|{counter:reqNumber} 
|Anwender sollen die Konfiguration der Sensoren und Aktuatoren des GPIO Simulators speichern und wiederverwenden können.
|3
|===

<<<
=== Projektplan
TODO: Zeitplan  einfügen (soll / ist)

<<<

=== Hardware
Zur Umsetzung unseres Projekts benötigen wir nebst einem Micro Computer noch diverse zusätzliche Hardware Komponenten. Dazu gehören vor allem eine Vielzahl von Sensoren und Aktuatoren. In der nachfolgenden Tabelle sind alle Komponenten festgehalten, welche uns zur Verfügung stehen.

.Micro Computer
[cols="1,7"]
|===
|Anzahl |Typ
|2 |https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/[Raspberry Pi 3 B+^]
|===

.Freenove Box
[cols="1,7"]
|===
|Anzahl |Typ
|1 |http://www.freenove.com/index.html[Freenove Ultimate Starter Kit for Raspberry Pi] (FNK0020)
|===

.Sensoren & Aktuatoren
[cols="1,7"]
|===
|Anzahl |Typ
|1 |https://wiki.seeedstudio.com/Grove_Base_Hat_for_Raspberry_Pi/[Grove Base Hat for Raspberry Pi^]
|3 |https://wiki.seeedstudio.com/Grove-TemperatureAndHumidity_Sensor/[Grove - Temperature & Humidity Sensor^]
|3 |https://wiki.seeedstudio.com/Grove-Touch_Sensor/[Grove – Touch^]
|3 |https://wiki.seeedstudio.com/Grove-Buzzer/[Grove – Buzzer^]
|2 |https://wiki.seeedstudio.com/Grove-Magnetic_Switch/[Grove - Magnetic Switch^]
|2 |https://wiki.seeedstudio.com/Grove-Rotary_Angle_Sensor/[Grove Rotary Angle Sensor^]
|2 |https://wiki.seeedstudio.com/Grove-Gesture_v1.0/[Grove - Gesture^]
|1 |https://wiki.seeedstudio.com/Grove-Button/[Grove - Button^]
|1 |https://wiki.seeedstudio.com/Grove-Light_Sensor/[Grove – Light Sensor^]
|1 |https://wiki.seeedstudio.com/Grove-Serial_Camera_Kit/[Grove - Serial Camera^]
|1 |https://wiki.seeedstudio.com/Grove-Light-Gesture-Color-Proximity_Sensor-TMG39931/[Grove – Light & Gesture & Color & Proximity Sensor^]
|1 |https://wiki.seeedstudio.com/Grove-I2C_Color_Sensor/[Grove - I2C Color Sensor^]
|1 |https://wiki.seeedstudio.com/Grove-Temperature_Sensor_V1.2/[Grove – Temperature Sensor^]
|1 |https://wiki.seeedstudio.com/Grove-Sound_Sensor/[Grove – Sound Sensor^]
|1 |https://wiki.seeedstudio.com/Grove-Ultrasonic_Ranger/[Grove – Ultrasonic Ranger^]
|1 |https://wiki.seeedstudio.com/Grove-LED_Strip_Driver/[Grove – LED Strip Driver^]
|1 |https://wiki.seeedstudio.com/Grove-125KHz_RFID_Reader/[Grove - RFID Reader^]
|1 |https://www.dexterindustries.com/pivotpi/[PivotPi Board^]
|1 |https://www.raspberrypi.org/products/camera-module-v2/[Raspberry Pi Camera V2^]
|===

=== Software
Nebst der verwendeten Hardware benötigen wir auch einige Software Bibliotheken zur Umsetzung unseres Projektes. Da der Simulator auf Java basieren soll, verwenden wir ausschliesslich Java Libraries zur Implementation der gewünschten Funktionalität.

==== Pi4J
Das Projekt Pi4J bietet vollzugriff auf die I/O Funktionalität des Raspberry Pi über eine objektorientierte Java API. Die Bibliothek abstrahiert die komplexe Hardware Programmierung und ermöglicht es Java Programmieren, sich auf die Implementation ihrer Logik zu konzentrieren.

* Exportieren und Importieren von GPIO Pins
* Konfigurieren der GPIO Pin Flussrichtung
* Lesen und schreiben des GPIO Pin State
* Pulse Width Modulation (Hardware & Software)
* Erstellen von GPIO State Listeners (Hardware Interrupt)
* Automatisches setzen eines Pin State bei Programmende (GPIO Shutdown)
* Senden und empfangen von Daten via serielle Schnittstelle (RS232)
* Support für Kommunikation über den I2C Bus (Inter-Integrated Circuit)
* Support für Kommunikation über den SPI Bus (Serial Peripheral Interface)
* Erweiterbarer GPIO Provider mit Support für GPIO Extension Boards
* Zugriff auf System- und Netzwerkinformationen des Raspberry Pi
* Wrapper Klassen für den direkten Zugriff auf WiringPi

Zu Projektstart war geplant, dass wir für unser Projekt die Pi4J Bibliothek in der aktuellsten Snapshot Version 1.4 verwenden werden, welche sich noch in Entwicklung befindet. Basis für diesen Entscheid war die Tatsache, dass Pi4J 1.4 Java 11 unterstützen soll. Die release Version 1.2 unterstützt lediglich Java 8 und ist deshalb weniger interessant. Im Verlauf unseres Projekts mussten wir diesen Entscheid jedoch überdenken. Es hat sich herausgestellt, dass der aktuelle Stand von Pi4J 1.4 nicht die gewünschte Stabilität für unser Projekt bieten kann. Bei der Arbeit an unseren Code Beispielen für den I2C LCD-Display sind wir auf Probleme gestossen, welche direkt mit der Pi4J Version zusammenhängen. Die I2C Schnittstelle wird in Kombination mit Java 11 nicht unterstützt. Zu diesem Problem gibt es bereits ein offenes GibHub Issue auf dem Pi4J Projekt, welches als Workaround ein Downgrade auf Java 8 vorschlägt. Grundsätzlich war es aber das Ziel, durch den Einsatz von Pi4J 1.4 Java 8 zu vermeiden. Zusätzlich sind die Device Klassen, welche ein einfaches Interface für die Ansteuerung einer Vielzahl von Sensoren und Aktuatoren erlaubt, in Pi4J 1.4 nicht mehr enthalten. Diese wurden von den Entwicklern aus dem Projekt entfernt, da die Device Implementation kaum von Anwendern benutzt wurden. Für den GPIO Simulator sind diese  Implementationen allerdings sehr interessant. Sie vereinfachen die Ansteuerung der Hardwarekomponenten und sind somit bestens für Studenten in den ersten Semestern geeignet.

Die Tatsache, dass in Pi4J 1.4 die Device Klassen fehlen und Java 11 wohl doch noch nicht komplett unterstütz wird, hat uns dazu bewegt, dass wir für unser Projekt auf die aktuelle Release Version 1.2 zurückgreifen.

==== Java
Ursprünglich wollten wir für unser Projekt Java 11 verwenden. Aus kompatibilitätsgründen mit Pi4J 1.2 setzen wir nun Java 8 als Basis ein.

==== Gradle
Um unser Projekt auf dem Raspberry Pi oder dem Computer zu bauen, verwenden wir das Build Management Tool Gradle in der Version 6.2.1. Die Konfiguration des Builds wird via das File `build.gradle` realisiert. Anschliessend kann das Projekt via Konsole gebaut werden.

==== Log4j 2
Die Log Funktionalität ist für unser Produkt essenziell. Die Umsetzung des Loggings ist Bestandteil des Minimum Viable Product. Ziel ist es, dass alle Interaktionen mit den GPIO Pins und Grove Adaptoren in einem geeigneten Format geloggt werden. Für Java stehen bereits diverse Logging Frameworks zur verfügung. Ein weit verbreiteter und beliebter Vertreter ist Log4j 2 von Apache. Es beitet die Funktionalität, Logs in eine Rolling File zu schreiben. Ein solches File eignet sich hervorragen für unsere Zwecke, weshalb wir uns für die Verwendung dieses Frameworks entschieden haben.

==== TODO: Cam Library

=== Analyse Applikationsdesign
Durch die Ergebnisse der Anforderungsanalyse haben wir viele neue Erkentnisse gewonnen. Diese Erkenntnisse bilden die Basis für technische Entscheidungen, welche wir in diesem Kapitel festhalten.

==== Benutzeroberfläche
Ein wichtiger Entscheid, welcher in diesem Projekt getroffen werden muss, ist die Integrationsart der Benutzeroberfläche des Simulators. Unsere Analyse hat gezeigt, dass es zwei verschiedene Möglichkeiten gibt, wie das User Interface mit dem Backend des Simulators verbunden werden kann. Einerseits können wir den Simulator als Stand-Alone Applikation zur Verfügung stellen, andererseits könnte der Simulator auch direkt als Dependance in das Projekt der Anwender inkludiert werden. Beide Vorgehensweisen sind im Kern gleich, haben aber ihre jeweiligen Vor- und Nachteile, auf welche wir in den folgenden Unterkapiteln eingehen.

===== Integration als Dependency
Bei diesem Integrationstyp wird der komplette Simulator zu einem festen Bestandteil des Raspberry Pi Projektes des Anwenders. Das Projekt umfasst nebst dem vom Anwender selbst geschriebenen Code, welcher schlussendlich auf dem Raspberry Pi ausgeführt werden soll, zusätzlich das gesamte User Interface des Simulators. Dies führt dazu, dass das Projekt des Anwenders um einiges grösser wird. Allerdings würde uns die direkte Integration unsere Arbeit erleichtern. Der Datenaustausch zwischen User Code und UI könnte über die uns bereits aus dem Unterricht bekannten UI Bindings von JavaFX implementiert werden. Des Weiteren gibt uns die Integration des Simulators in das Projekt des Anwenders mehr Freiheit bezüglich der Konfiguration des Simulators. Einerseits könnte das User Interface gleich aus dem Code des Anwenders generiert werden, andererseits könnte die Konfiguration der GPIO Schnittstellen auch im Simulator selbst erfolgen.

[.underline]#*Konfiguration via Code*#

Unter Verwendung dieser Konfigurationsart entscheidet der Code des Benutzers, welche Sensoren und Aktuatoren an welche virtuellen Anschlüsse des Simulators angeschlossen werden. Sobald der Benutzer den Code unter Verwendung des GPIO Simulators startet, generiert der Simulator das UI gemäss den im Code verwendeten Pins, Sensoren und Aktuatoren. Ein wesentlicher Vorteil dieses Konfigurationstyps ist sicher die Einfachheit der Anwendung. Der Benutzer muss sich lediglich um seinen Code kümmern. Genau so wie die Sensoren im Code verwendet werden, werden diese auch im Simulator angezeigt. Es ist somit ausgeschlossen, dass Pins verwendet werden, welche nicht mit Sensoren oder Aktuatoren verbunden sind. Dies kann aber auch ein Nachteil sein, da diese Konfigurationsart nicht wirklich der Realität entspricht, welche man in einem IoT Projekt antrifft. Dort ist der Anwender für die Verkabelung der Sensoren und Aktuatoren mit dem Raspberry Pi selbst verantwortlich. Es kann durchaus passieren, dass beispielsweise die falschen Pins verbunden werden. Dieser Aspekt würde unter Verwendung der aus dem Code generierten Konfiguration verloren gehen.

.Dependency Integration mit Konfiguration im Code 
image::Dependency_Integration_Code.png[width=75% Design Dependecy]

[.underline]#*Konfiguraiton via Simulator*#

Bei diesem Konfigurationstyp wird die Konfiguration direkt im Simulator vorgenommen. Nachdem ein Anwender seinen Code Ausführt, öffnet sich das UI des GPIO Simulators. Der Benutzer kann nun via Drag and Drop Sensoren und Aktuatoren im dafür vorgesehenen Bereich platzieren und diese mit den GPIO oder Grove Pins des virtuellen GroveHat verbinden. Nachdem der Benutzer die Konfiguration abgeschlossen hat, kann er dies über einen Button bestätigen und die Simulation startet. Der Vorteil dieses Konfigurationstyps liegt ganz klar in der Realitätsnähe, welche über die Konfiguration via Code fehlt. Der Benutzer hat die Möglichkeit, Sensoren und Aktuatoren falsch anzuschliessen und muss dem Problem selbst nachgehen. Dies erhöht den Lerneffekt und trägt zum Verständnis bei. Nachteil ist allerdings, dass die Konfiguration erst nach dem Starten des Codes gemacht werden kann.

.Dependency Integration mit Konfiguration im Simulator
image::Dependency_Integration_Simulator.png[width=75% Design Dependecy]

===== Integration als Standalone Applikation
Bei diesem Integrationstyp wird der Simulator zu einer separaten Applikation, die auf einem eigenen Prozess läuft. Der Code des Anwenders läuft bei seiner Ausführung komplett unabhängig vom Simulator selbst. Die Unabhängigkeit der Projekte macht die Kommunikation zwischen den beiden Programmen komplizierter, da ein neuer indirekter Weg für die Datenübertragung gefunden werden muss. Eine Stand-Alone Applikation hätte aber den Vorteil, dass die Konfiguration des Simulators nicht erst zur Laufzeit stattfinden müsste. Man könnte den Simulator also starten und konfigurieren, ohne den Code bereits geschrieben zu haben. Ein Benutzer könnte dann die Simulation starten und gegen den Simulator programmieren. Immer wenn der Anwender seinen Code ausführt, kann er direkt im Simulator sehen, ob der Code die gewünschte Wirkung hat. Der Entwickler bekommt also Echtzeit Feedback. Dieser Integrationstyp simuliert die Realität sicher am besten, da der Raspberry Pi auch eine separate Instanz ist, an welche unabhängig von der Entwicklungsumgebung Sensoren und Aktuatoren angeschlossen werden können.

.Stand-Alone Integration 
image::Standalone_Integration.png[width=75% Design Standalone]

==== TODO: Entscheidung dokumentieren

<<<


=== Simulatiosstrategie: 1. Iteration
Nebst der Frage, wie wir den Simulator integrieren möchten, müssen wir uns darüber Gedanken machen, wie wir den Switch zwischen Simulator und Hardware für den Benutzer möglichste einfach gestalten können. Grundsätzlich ist es das Ziel, dass der Benutzer den Code nur an einer einzigen Stelle ändern muss, um zwischen Simulator und Hardware zu wechseln. Auch denkbar wäre eine Konfiguration ausserhalb des Codes mittels Konfigurationsdatei.

==== Erste Idee
Zu Beginn des Projektes war es unser Plan, das Factory Design Pattern zu verwenden, um zwischen der Simulation und dem effektiven Hardwarezugriff via Pi4J zu differenzieren. Pi4J implementiert nämlich selbst das Factory Pattern, was wir und zu Nutzen machen wollten. In einem IoT Projekt mit Pi4J muss immer zuerst die gewünschte Factory instanziiert werden. Zum Beispiel GpioFactory, I2CFactory oder die SerialFactory. 

Der Backend Code des Simulator und Pi4J wären dann in einem Projekt gekapselt und der Anwender man müsste nur im obersten Zugriffspunkt eine kleine Veränderung vornehmen, um zwischen Simulator und Pi4J zu wechseln.

.Simulator Factory
image::GpioSimulatorFactory_Idee.png[width=75% Factory Idee]


Zur Umsetzung des Factory Pattern hätten wir eine Globale Factory implementieren müssen, von welcher sowohl Pi4J als auch unser Simulator erbt. Im oben abgebildeten Diagramm wird diese Factory durch die Klasse `GpioSimulatorFactory` verkörpert. Leider hat sich diese Vorgehensweise nicht bewährt, da wir die Klassen in Pi4J nicht bearbeiten können.

Um das Problem mit der Bearbeitung des Codes von Pi4J zu umgehen, könnten wir einen Fork des GitHub Projektes machen und auf diesem Fork die nötigen Anpassungen vornehmen. Wir hätten somit eine FHNW-Version von Pi4J. Allerdings würde dies einen sehr grossen initialen Aufwand bedeuten, was den Rahmen unseres IP 5 Projektes sprengen würde. Des Weiteren müsste der gesamte Code in Zukunft gewartet und modernisiert werden.

==== Analyse Pi4J
Da eine FHNW-Version von Pi4J nicht in Frage kommt, müssen wir eine andere Möglichkeit finden, wie wir die Simulation implementieren können. Zunächst gilt es, das gesamte Pi4J-Paket zu analysieren. Die Analyse soll uns dabei unterstützen, neue Simulationsstrategien zu finden.

Das Projekt Pi4J ist aufgeteilt in:

. *pi4j-core*: +
Stellt alle Klassen und Methoden zur Verfügung, um direkt auf die GPIO Pins zuzugreifen. 
. *pi4j-device*: +
Ist ein Abstraktions Layer, der die Nutzung von Sensoren und Aktuatoren vereinfacht, indem eigene Klassen zur Verfügung gestellt werden.
. *pi4j-distribution*: +
Enthält Scripts und Dateien, welche man für die Installation und Deinstallation benötigt.
. *pi4j-example*: + 
Enthält Beispiele für Verschiedene Devices, die mit Pi4J angesteuert werden können.
. *pi4j-gpio-extension*: +
Enthält Software für die erleichterte Verwendung von Extenstion Boards wie z.B PiFace.
. *pi4j-native*: +
Enthält native Scripts für weitere Entwicklungsboards wie NanoPi oder BananaPi.

In unserem Projekt benötigen wir ausschliesslich die ersten beiden Projekte. pi4j-core und pi4j-device. Alle weiteren Bestandteile von Pi4j benötigen wir nicht.

==== Mögliche Vorgehensweisen
Auf Basis unserer Analyse gilt es eine Entscheidung zu treffen, wie wir den Switch zwischen Simulator uns Hardware technisch umsetzen möchten. Wir haben uns zusammen mit unseren Projektpartnern auf die folgenden drei Möglichkeiten geeinigt.

==== Simulator = Tutorial
Bei dieser Vorgehensweise entfällt der Simulator Aspekt unseres Projektes. Das Ziel unserer Arbeit wäre es nicht mehr, einen Simulator für Sensoren und Aktuatoren auf Basis von Pi4J zu implementieren, sondern das zur Verfügung stellen von Abstraktionen für Sensor- und Aktuator-Zugriffe begleitet durch ein informatives Tutorial. Der Fokus des Projektes liege dann in der Unterstützung von Studentinnen und Studenten der ersten Semester bei der Umsetzung Ihrer IoT Projekte durch die von uns gesammelten Erfahrungen.

Wenn wir uns für diese Vorgehensweise entscheiden, müssen wir für die Wichtigsten uns zur Verfügung stehenden Sensoren und Aktoren Abstraktionen sowie Beispiele sowie ausarbeiten, welche den Studierenden als direkte Referenz dienen können. Durch das zur Verfügung stellen von guten, konkreter Code Beispielen müssen sich die Studierenden weniger mit der Hardware selbst beschäftigen und können somit besser parallel am Projekt arbeiten.

==== Simulator auf Ebene GPIO
Bei dieser Vorgehensweise würden wir das Ziel verfolgen, alle Funktionen von Pi4J-Core simulieren zu können. Da Pi4J-Core der Kern von Pi4J ist und dieses Packet direkt mit den GPIO Pins arbeitet, bieten sich die GPIO Pins als geeignete Docking-Station für unseren Simulator an. Wenn wir die GPIO Pins simulieren können, so könnten wir letztlich sämtliche GPIO Befehle simulieren und somit jegliche Projekte komplett unterstützt.

Allerdings erachten wir die Simulation auf dieser Ebene als schwierig umzusetzen. Die Schwierigkeit bestünde hauptsächlich im Umfang der Pi4J-Core Library. Die Bibliothek ist sehr gross und es ist für uns unvorhersehbar, welche Bereiche wirklich von den Studenten benötigt werden würden. Wir mussten dies bereits bei der Arbeit an den Beispielen für die Sensoren und Aktoren feststellen. Selbst bei der Verwendung eines einfachen Buttons dringt man beim Debuggen sehr schnell in die Tiefen von Pi4J ein und landet in diversen weiteren Libraries, welche im Projekt inkludiert sind.  Beispielsweise wird für manche Geräte WiringPi benötigt. Eine Library, welche in Pi4J inkludiert ist.

Eine Simulation auf GPIO Ebene würde dazu führen, dass der Simulator sehr umfangreich wäre und ein höheres Risiko bestünde, dass die Menge der Arbeit im Backend explosionsartig zunehmen könnte. Es wäre durchaus möglich, dass durch einen möglichen Zeitverlust an der Arbeit im Backend die Usability und die Arbeit an der Benutzeroberfläche zu kurz kommt oder kaum begonnen werden kann.

Wenn wir uns für dieses Vorgehen entscheiden, müssen wir damit umgehen können, dass das Projekt womöglich bis zur Deadline nicht im gewünschten Status ist.

==== Simulator auf Ebene Device
Bei dieser Vorgehensweise würden wir das Ziel verfolgen, alle Funktionen von Pi4J-Device simulieren zu können. Der Umfang des Pi4J-Device Layer ist definitiv überschaubarer derjenige von Pi4J-Core. Pi4J-Device bietet direkt Klassen für einzelne Devices an, welche die nötigen GPIO Zugriffe abstrahieren.

Ansetzen würden wir bei dieser Implementationsart also direkt bei den Device Beispielen von Pi4J. Für die oft verwendeten Devices würden wir eine eigene Klasse implementieren, welche die Simulation übernimmt. Die Studentinnen und Studenten könnten in Ihrem Code wählen, welches Device sie verwenden möchten. Entweder die durch uns implementierte Simulation oder das Pi4J-Device, welches direkt auf die Hardware zugreift. Dies hätte für uns den Vorteil, dass die Arbeit im Backend im Vergleich zur Simulation der GPIO Pins wesentlich geringer wäre und weniger Risiken birgt.

Leider haben wir während unseren Recherchen festgestellt, dass Pi4J-Device in zukünftigen Releases nicht mehr weitergeführt wird. Aus diesem Grund bräuchte man eine eigene Pi4J-Device Version, welche dann von der FHNW weitergeführt werden könnte, wenn beispielsweise neue Devices benötigt werden.

Wenn wir uns für dieses Vorgehen entscheiden, brauchen wir also eine eigene FHNW-Version von Pi4J Device, welche weitergeführt und gewartet werden muss.

==== Entscheidung
Letztendlich haben wir uns für die Simulation auf Ebene von Pi4J-Device entschieden, da das Risiko und der Umfang der Simulation der GPIO Pins schlicht und einfach zu unvorhersehbar gewesen wäre. Der Tutorial-Aspekt des Projektes geht dabei auch nicht verloren, da wir für alle Geräte 3 Beispiele machen werden:

. Ein Beispiel, welches direkt mit den GPIO Pins arbeitet.
. Ein Beispiel, welches die Pi4J-Device Klasse des Geräts verwendet.
. Ein Beispiel, welches den GPIO-Simulator verwendet.

Anhand der zur Verfügung gestellten Beispielen können sich die angehenden Studentinnen und Studenten bestens für die von Ihnen präferierte Vorgehensweise für ihr Projekte entscheiden und lernen durch das Studieren der Beispielcodes sicherlich vieles dazu, was Ihnen später bei der Implementierung hilft.

=== Simulatiosstrategie: 2. Iteration
Während er Arbeit am Simulator auf Basis von Pi4J-Device sind wir nach einiger Zeit auf neue Hindernisse gestossen, welche sich als unüberwindbar herausgestellt haben. Deshalb mussten wir unser Vorgehen erneut überdenken.

==== Problembeschreibung
Um die Devices simulieren zu können, haben wir eine Factory erstellt, welche im Konstruktor einen Boolean annimmt. Dieser Boolean bestimmt dann, welcher Typ von Device zurückgegeben wird. Entweder ein Pi4J-Device oder unser Custom Simulator Device. Der Untere Java Code zeigt einen solchen Konstruktor für das LED Device.

[source,java]
----
public LEDBase getLED(GpioPinDigitalOutput pin) {
    LEDBase led = simulator ? new GpioLEDSimulator(pin) : new GpioLEDComponent(pin);
    return led;
}
----

Das Simulator LED Device unterstützt im Moment lediglich die Funktion blink(), welche wiederum die Funktionen on() und off() aufrufen. In den beiden letzteren Funktionen haben wir jeweils einfach den aktuellen Status mittels Log4j 2 auf die Konsole sowie in ein Rolling File geschrieben.

[source,java]
----
@Override
public Future<?> blink(long delay) {
    return executor.submit(() -> {
        while (true) {
            if (isOn())
                off();
            else
                on();
            Thread.sleep(delay);
        }
    });
}
----

Um unsere Implementation zu testen, haben wir die Klasse `BlinkLedDevice` so modifiziert, dass wir eine `LEDBase` vom Typ `GpioLEDSimulator` erhalten. Dies haben wir durch den im Konstruktor der Factory übergebenen Boolean festgelegt. Auf dem Simulator Device Rufen wir nun die `bink()` Funktion auf.

[source,java]
----
public class BlinkLedDevice extends Example {

    public BlinkLedDevice(int key, String title) {
        super(key, title);
    }

    @Override
    public void execute() throws Exception {
        GpioFactory.setDefaultProvider(new RaspiGpioProvider(RaspiPinNumberingScheme.BROADCOM_PIN_NUMBERING));
        final GpioController gpio = GpioFactory.getInstance();

        GpioPinDigitalOutput led = gpio.provisionDigitalOutputPin(RaspiBcmPin.GPIO_02, "Blinking LED" , PinState.LOW);
        led.setShutdownOptions(true, PinState.LOW);
        
        // new GpioSimulatorFactory(true) => Is a Simulator Factory
        GpioSimulatorFactory gpioSimulatorFactory = new GpioSimulatorFactory(true);
        LEDBase ledComponent = gpioSimulatorFactory.getLED(led);

        Console console = new Console();
        console.promptForExit();

        long delay = 1000;
        console.println("start blinking with "+delay+" delay");

        ledComponent.blink(delay);

        gpio.shutdown();
    }
}
----

Beim Testen unseres Codes mussten wir allerdings feststellen, dass diverse Pi4J Aufrufe nicht funktionieren, welche für die Ausführung des Codes auf dem Raspberry Pi allerdings immer von Nöten sein werden. Beispielsweise ist es uns nicht möglich, über die statische Klasse `GpioFactory` den Default-Provider zu setzen, wenn wir als Provider den `RaspiGpioProvider` verwenden. Dieser greift in seinen Tiefen auf WiringPi zu. WiringPi erwartet dann gewisse Files an einem bestimmten Ort auf einem Linux System. Diesen Pfad findet er auf einem Windows Rechner natürlich nicht und wirft deshalb bei der Ausführung des Codes folgende Fehlermeldung:

[source]
----
SCHWERWIEGEND: Unable to load [libpi4j.so] using path: [/lib/raspberrypi/dynamic/libpi4j.so]
java.lang.IllegalArgumentException: The path has to be absolute, but found: \lib\raspberrypi\dynamic\libpi4j.so
----

Wenn wir unseren Code im Simulator Modus auf dem Raspberry Pi laufen lassen, funktioniert die Simulation problemlos. Wir erhalten dann den gewünschten Log.

[source]
----
10:16:37.993 [pool-2-thread-1] INFO  gpiosimulator.GpioSimulatorFactory - LED is on
10:16:38.996 [pool-2-thread-1] INFO  gpiosimulator.GpioSimulatorFactory - LED is off
10:16:39.997 [pool-2-thread-1] INFO  gpiosimulator.GpioSimulatorFactory - LED is on
10:16:40.999 [pool-2-thread-1] INFO  gpiosimulator.GpioSimulatorFactory - LED is off
10:16:42.000 [pool-2-thread-1] INFO  gpiosimulator.GpioSimulatorFactory - LED is on
----

Ein möglicher Workaround wäre das Benutzen eines anderen Providers anstelle des RaspiGpioProvider. Pi4J stellt nämlich einen SimulatedGpioProvidre zur Verfügung.

[source,java]
----
GpioFactory.setDefaultProvider(new SimulatedGpioProvider());
----

Momentan wissen wir, dass dieser Provider das gleiche Interface implementiert wie der RaspiGpioProvider. Allerdings retourinert er überall einfach null oder löst bestimmte Events schlicht nicht aus. Wenn wir diesen Provider in einem unserer GPIO Beispiele verwenden, passiert einfach nichts.

Wir haben uns über das weitere Vorgehen Gedanken gemacht und haben die folgenden weiteren Vorgehensweisen erarbeitet.

==== SimulatedGpioProvider verwerden
Generell gehen wir davon aus, dass wir unter Verwendung des SimulatedGpioProvider den Simulator wie geplant implementieren können. Der Benutzer müsste seinen Code jedoch nicht nur an einer Stelle anpassen, sondern an mindestens zwei. Das wäre aber wohl noch verkraftbar.

Durch unsere bisherig gesammelten Erfahrungen mit den Sensoren und Aktuatoren sind wir uns aber unsicher, wie viel eine Simulation dem Studenten schlussendlich überhaupt an Mehrwert bringt. Wenn wir beispielsweise ein I2C LCD simulieren würden, könnten wir lediglich den Text an einem bestimmten Ort (Konsole / File / Simulator) weitergeben und anzeigen. Ob nun die Verkabelung stimmt und der Text in die richtigen Bytes zerlegt wird, können wir kaum testen oder sicherstellen.

==== Der Simulator wird zum ausführlichen Tutorial
Diesen Ansatz haben wir bereits besprochen. Resultat der Projektarbeit wären eine Art Guide für die Verwendung von Pi4J Devices, welche wir mit unseren eigen FHNW-Devices ergänzen können. Zusätzlich würden wir noch den Grove Hat und dessen Adapter unterstützen. Wir bieten dem Studenten somit stabile Beispiele, dessen Funktionsfähigkeit auf der verwendeten Hardware garantiert werden kann. Unserer Meinung nach wäre dieser Ansatz wesentlich gewinnbringender für die Studierenden als eine oberflächliche Simulation. Die schwierige Arbeit bei einem IoT Projekt hängt nämlich immer von der verwendeten Hardware ab.

==== Entscheidung
Gemeinsam mit unseren Coaches haben wir uns dafür entschieden, ein ausführliches Tutorial zu schreiben, da es schlussendlich erfolgsversprechender ist und einen grösseren Nutzen für die Studierenden hat.

Das Tutorial soll ein separates Dokument sein und muss am Anfang ein Setup Guide für den Raspberry Pi enthalten. Alternativ kann auch ein Image für die angehenden Studenten zur Verfügung gestellt werden, um das Setup zu erleichtern.

Bei den Code Beispielen muss ausserdem darauf geachtet werden, dass sie nicht zu komplexe Themen wie Asynchronität ansprechen, da solche Themen den Rahmen eines Projektes für das erste und zweite Semester sprengen.

== Praktischer Teil

=== Asynchronität und Multi-Threading

=== Button

=== Grove Hat

=== Grove Serial Camera
Die Grove Serial Camera besteht aus einem Kamera Modul und einem Control Board, welches die Kommunikation zwischen der Kamera und dem Raspberry Pi über den Serial Bus ermöglicht. Die Kamera benötigt eine Spannung von 5 Volt, weshalb sie leider nicht mit unserem Grove Hat kompatibel ist. Dieser liefert nur 3.3 Volt an die Grove Adapter. Um die Kamera dennoch nutzen zu können, muss sie via Jumper Kabeln an den Serial Port des Raspberry Pi angeschlossen werden. Weitere Informationen zur Verkabelung können dem Tutorial entnommen werden.

==== Protokoll
Die Datenübermittlung zwischen Kamera und Pi erfolgt über den Serial Bus und das OV528 Protokoll. Die einzelnen Kommandos umfassen jeweils 6 Bytes, welche zusammen als Paket übermittelt werden. Das nachfolgende Beispiel zeigt das SYNC Kommando, welches jeweils zu Beginn der Kommunikation vom Pi ausgesendet wird. Folgende Bytes werden übermittelt: AA0D00000000h.

.SYNC Kommando
image::Grove_Serial_Camera_SYNC_Command.png[width=75% Grove Serial Camera SYNC]

==== Verbindung mit der Kamera aufbauen
Bevor Befehle an die Kamera gesendet werden können, muss eine Verbindung zwischen Kamera und Raspberry Pi etabliert werden. Dazu wird vom Host mehrmals ein SYNC Kommando auf den Serial Port geschrieben und auf eine Antwort von der Kamera gewartet. Durchschnittlich antwortet die Kamera nach 25 SYNC Kommandos mit einem ACK (AA0E0Dxx0000h). Auf die Empfangsbestätigung folgt das Kommando, welches die Kamera bestätigt. In diesem Fall das SYNC Kommando (AA0D00000000h). Gibt die Kamera nach 60 SYNC Befehlen noch immer keine Antwort, kann davon ausgegangen werden, dass etwas mit der Verkabelung der Kamera nicht stimmt oder der Controller der Kamera defekt ist.

.Verbindungsaufbau
image::Grove_Serial_Camera_Initialisation.png[width=75% Grove Serial Camera Connection]

In unserer Java Klasse haben wir den Verbindungsaufbau in einer eigenen Funktion realisiert, welche vom jeweiligen Konstruktor aufgerufen wird. In einer While-Schlaufe wird das SYNC Kommando solange an die Kamera gesendet, bis diese eine Antwort auf den Serial Bus geschrieben hat. Ist dies nach 60 Versuchen nicht der Fall, wird die Initialisierung mit einem Fehler abgebrochen. Hat die Kamera eine Antwort gesendet, wird diese auf Ihre Korrektheit überprüft. Die ersten sechs Bytes müssen dem ACK Kommando entsprechen (AA0E0Dxx0000h). Bei den nächsten sechs Bytes muss es sich um das SYNC Kommando handeln (AA0D00000000h). Sofern dies der Fall ist, war der Verbindungsaufbau erfolgreich. Die Kamera ist nun bereit für die Entgegennahme von weiteren Befehlen.

[source,java]
----
include::{sourcedir}/fhnwgpio/components/SerialCameraComponent.java[tags=SerialCamInit]
----

==== JPEG Foto anfordern
Nach dem erfolgreichen Verbindungsaufbau ist die Kamera bereit für das Schiessen von Bildern. Unsere Implementation stellt Bilder im JPEG Format in der Auflösung 640 x 480 zur Verfügung. Hierbei handelt es sich um die maximale Auflösung der Kamera. Theoretisch können auch Bilder in anderen Grössen und Formaten von der Kamera angefordert werden. Diese Formate werden von uns jedoch nicht unterstützt.

Um ein Bild von der Kamera zu erhalten, sind mehrere einzelne Schritte, Befehle und Bestätigungen nötig. Diese sind im folgenden Diagramm ersichtlich.

.Ablauf der Bildanforderung
image::Grove_Serial_Camera_Get_Picture.png[width=75% Grove Serial Camera Get Picture]

==== Bildgrösser ermitteln
Zur Ermittlung der Bildgrösse wird die gewünschte Paketgrösse der einzelnen Pakete benötigt. Die Paketgrösse kann vom Anwender im Bereich von 16 bis 2048 Bits definiert werden. Die Default Paketgrösse ist 512 Bits.

Als erster Schritt wird die zuvor definierte gewünschte Paketgrösse an die Kamera gesendet und es wird auf eine Empfangsbestätigung der Kamera gewartet.

Anschliessend wird das Snapshot Kommando an die Kamera gesendet. Dieses Kommando bereitet die Kamera auf das Erzeugen eines Bildes vor. Auch hier wird wieder auf eine Empfangsbestätigung der Kamera gewartet.

Zu guter Letzt wird der Befehl zur JPEG Generierung an die Kamera übermittelt. Die Kamera antwortet auf dieses Kommando mit einer Empfangsbestätigung gefolgt von der Anzahl Bytes des Bildes, welches geschossen wurde.

[source,java]
----
include::{sourcedir}/fhnwgpio/components/SerialCameraComponent.java[tags=SerialCamGetPictureLength]
----

==== Bild Pakete empfangen
Nachdem die Bildgrösse von der Kamera ermittelt wurde, kann der Host Paket für Paket von der Kamera über den Serial Bus anfordern. Wir fordern solange Pakete von der Kamera an, bis wir das letzte Paket von der Kamera erhalten haben. Das letzte Paket erkennen wir anhand der letzten zwei Bytes. Handelt es sich bei diesen um 0xFF gefolgt von 0xD9, wurde das komplette JPEG übermittelt. Bei den zwei Bytes handelt es sich nämlich um den Footer eines jeden JPEGs.

Da es bei der Übermittlung von Paketen immer zu Fehlern kommen kann, stellt das OV528 Protokoll einen Kontrollmechanismus zur Verfügung, über welchen Fehler identifiziert werden können. Bei den zwei letzten Bytes eines jeden Pakets handelt es sich um eine Prüfsumme, mit welchen die übermittelten Bilddaten überprüft werden können. Die Prüfsumme muss exakt der Summe der einzelnen übermittelten Bytes entsprechen. Ist dies der Fall, fordern wir das nächste Paket von der Kamera an. Stimmt die Prüfsumme jedoch nicht mit der Summe aller Bild-Bytes überein, fordern wir das fehlerhafte Paket erneut von der Kamera an. Damit kann sichergestellt werden, dass das erhaltene Bild immer fehlerfrei ist.

[source,java]
----
include::{sourcedir}/fhnwgpio/components/SerialCameraComponent.java[tags=SerialCamGetPicture]
----

=== Raspbery Pi Camera V2

=== I2C Interface

<<<

:sectnums!:
== Schluss

<<<
== Literaturverzeichnis

<<<
== Ehrlichkeitserklärung

<<<
== Anhang
